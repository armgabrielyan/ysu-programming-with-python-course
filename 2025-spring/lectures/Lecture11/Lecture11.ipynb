{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91a9302f",
   "metadata": {},
   "source": [
    "# Programming with Python\n",
    "\n",
    "## Lecture 11: Concurrency 3\n",
    "\n",
    "### Armen Gabrielyan\n",
    "\n",
    "#### Yerevan State University / ASDS\n",
    "\n",
    "#### 03 May, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540d4bc3",
   "metadata": {},
   "source": [
    "# Multi-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edd2606",
   "metadata": {},
   "source": [
    "## `multiprocessing` module\n",
    "\n",
    "### Overview\n",
    "\n",
    "The `multiprocessing` module provides a way to create new processes using an API similar to the `threading` module. Unlike threads, it uses separate subprocesses, which allows it to bypass the Global Interpreter Lock (GIL) and take full advantage of multiple CPU cores. This enables true parallel execution and works on both POSIX systems and Windows.\n",
    "\n",
    "In addition to thread-like functionality, `multiprocessing` includes features not found in the `threading` module. One notable feature is the `Pool` class, which simplifies running a function in parallel across a collection of inputs—this is known as data parallelism.\n",
    "\n",
    "`multiprocessing.Process` objects represent activity that is run in a separate process. The `multiprocessing.Process` class has equivalents of all the methods of `threading.Thread`.\n",
    "\n",
    "The `if __name__ == '__main__'` part is necessary in multi-processing as you can see in the following example. This is to make sure that the main module can be safely imported by a new Python interpreter without causing unintended side effects (such as starting a new process).\n",
    "\n",
    "**See practical example 1**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4b1c6",
   "metadata": {},
   "source": [
    "### Contexts and start methods\n",
    "\n",
    "#### 1. **`spawn`**\n",
    "- **How it works:** Starts a *fresh Python interpreter process*.\n",
    "- **Pros:** Clean slate—only essential resources are inherited.\n",
    "- **Cons:** Slower startup.\n",
    "- **Default on:** **Windows** and **macOS**.\n",
    "\n",
    "#### 2. **`fork`**\n",
    "- **How it works:** Uses `os.fork()`. Child is a clone of the parent.\n",
    "- **Pros:** Very fast.\n",
    "- **Cons:** Not safe with multithreaded processes.\n",
    "- **Default on:** Most **Linux**/POSIX systems (but **changing in Python 3.14**).\n",
    "- **Deprecated** for multi-threaded environments since Python 3.12 because forking a multi-threaded process is problematic.\n",
    "\n",
    "#### 3. **`forkserver`**\n",
    "- **How it works:** Starts a **server** process which handles forking. As it is single-threaded, it is safer to use `fork` method.\n",
    "- **Pros:** Safer than `fork`, faster than `spawn`. No excess resources inherited.\n",
    "- **Cons:** Requires OS support for file descriptor passing.\n",
    "- **Available on:** POSIX with certain features (e.g., Linux).\n",
    "\n",
    "Here are two ways to select a start method.\n",
    "\n",
    "#### Option 1: `set_start_method()` (set once per program)\n",
    "\n",
    "```python\n",
    "import multiprocessing as mp\n",
    "\n",
    "def foo(q):\n",
    "    q.put('hello')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mp.set_start_method('spawn')  # 'spawn', 'fork', or 'forkserver'\n",
    "    q = mp.Queue()\n",
    "    p = mp.Process(target=foo, args=(q,))\n",
    "    p.start()\n",
    "    print(q.get())\n",
    "    p.join()\n",
    "```\n",
    "\n",
    "#### Option 2: `get_context()` (preferred for libraries or multiple modes)\n",
    "\n",
    "This avoids conflicts with other parts of the app or external libraries.\n",
    "\n",
    "```python\n",
    "import multiprocessing as mp\n",
    "\n",
    "def foo(q):\n",
    "    q.put('hello')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ctx = mp.get_context('spawn')\n",
    "    q = ctx.Queue()\n",
    "    p = ctx.Process(target=foo, args=(q,))\n",
    "    p.start()\n",
    "    print(q.get())\n",
    "    p.join()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31660459",
   "metadata": {},
   "source": [
    "## Inter-Process Communication (IPC)\n",
    "\n",
    "Inter-Process Communication (IPC) refers to mechanisms that allow processes to exchange data and coordinate their actions. These mechanisms are essential for building complex systems where multiple processes need to work together. Synchronization, shared memory, queues and pipes are some examples for organizing IPC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bb816a",
   "metadata": {},
   "source": [
    "### Synchronization between processes\n",
    "\n",
    "The `multiprocessing` module offers the same synchronization tools as the `threading` module. For example, the following example shows a race condition by incrementing a shared counter from multiple processes without a lock.\n",
    "\n",
    "**See practical example 2**.\n",
    "\n",
    "We can use **lock** to safely update the shared counter value and prevent race conditions.\n",
    "\n",
    "**See practical example 3**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edbc310",
   "metadata": {},
   "source": [
    "# Exchanging objects between processes\n",
    "\n",
    "When using multiple processes, one generally uses message passing for communication between processes and avoids having to use any synchronization primitives like locks.\n",
    "\n",
    "For passing messages one can use `multiprocessing.Pipe()` (for a connection between two processes) or a queue (which allows multiple producers and consumers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e22b5e",
   "metadata": {},
   "source": [
    "### `multiprocessing.Pipe([duplex])`\n",
    "\n",
    "Returns a pair `(conn1, conn2)` of `multiprocessing.connection.Connection` objects representing the ends of a pipe.\n",
    "\n",
    "If `duplex` is `True` (the default) then the pipe is bidirectional. If `duplex` is `False` then the pipe is unidirectional: `conn1` can only be used for receiving messages and` conn2` can only be used for sending messages.\n",
    "\n",
    "Note that data in a pipe may become corrupted if two processes (or threads) try to read from or write to the same end of the pipe at the same time. Of course there is no risk of corruption from processes using different ends of the pipe at the same time.\n",
    "\n",
    "The `send()` method serializes the object using `pickle` and the `recv()` re-creates the object.\n",
    "\n",
    "#### Key Characteristics\n",
    "\n",
    "- **Byte stream:** Pipes typically handle an unstructured stream of bytes. The writing process sends bytes, and the reading process receives bytes, often without inherent message boundaries. The reader needs to know how to interpret the byte stream (e.g., reading until a newline character or reading a fixed number of bytes).\n",
    "- **Kernel-managed buffer:** The operating system manages a buffer for the pipe. If the writer produces data faster than the reader consumes it, the data accumulates in the buffer. If the buffer fills up, the writer will block (wait) until the reader consumes some data. Conversely, if the reader tries to read from an empty pipe, it will block until the writer sends data.\n",
    "- **Synchronization:** The blocking behaviour provides implicit synchronization between the producer (writer) and consumer (reader).\n",
    "\n",
    "**See practical example 4**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaaaa6c",
   "metadata": {},
   "source": [
    "### Queues\n",
    "\n",
    "- Similar to pipes, these are another mechanism for Inter-Process Communication (IPC).\n",
    "- **Message-Oriented:** Unlike pipes which handle byte streams, message queues typically handle discrete messages. The sender enqueues a whole message, and the receiver dequeues a whole message. This preserves message boundaries.\n",
    "- **Many-to-Many:** Often, multiple processes can write to the same queue, and multiple processes can read from it (though often a message is consumed by only one reader).\n",
    "\n",
    "In Python, the `multiprocessing.Queue`, `multiprocessing.SimpleQueue` and `multiprocessing.JoinableQueue` types are multi-producer, multi-consumer FIFO queues modelled on the `queue.Queue` class in the standard library. They differ in that `multiprocessing.Queue` lacks the `task_done()` and `join()` methods introduced into Python 2.5’s `queue.Queue` class.\n",
    "\n",
    "If you use `JoinableQueue` then you must call `JoinableQueue.task_done()` for each task removed from the queue or else the semaphore used to count the number of unfinished tasks may eventually overflow, raising an exception.\n",
    "\n",
    "One difference from other Python queue implementations, is that `multiprocessing` queues serializes all objects that are put into them using `pickle`. The object return by the `get` method is a re-created object that does not share memory with the original object.\n",
    "\n",
    "Multi-processing queues are thread and process safe.\n",
    "\n",
    "**See practical example 5**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2404d597",
   "metadata": {},
   "source": [
    "## Sharing state between processes\n",
    "\n",
    "When doing concurrent programming it is usually best to avoid using shared state as far as possible. This is particularly true when using multiple processes.\n",
    "\n",
    "However, `multiprocessing` provides a couple of ways of doing so, namely shared memory and server process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424b00cb",
   "metadata": {},
   "source": [
    "### Shared memory\n",
    "\n",
    "In Python multiprocessing, shared memory allows multiple processes to access and modify the same data without copying it between processes — improving performance and coordination.\n",
    "\n",
    "Normally, when a new process is spawned, it gets its own copy of data (due to process isolation). Shared memory avoids this by letting processes point to the same data block.\n",
    "\n",
    "In Python, this can be done with shared `ctypes` objects.\n",
    "\n",
    "[`ctypes`](https://docs.python.org/3/library/ctypes.html) is a foreign function library for Python. It provides C compatible data types, and allows calling functions in DLLs or shared libraries. It can be used to wrap these libraries in pure Python.\n",
    "\n",
    "#### `multiprocessing.Value(typecode_or_type, *args, lock=True)`\n",
    "\n",
    "Creates a shared object in memory, typically wrapped with a synchronization mechanism. This object is used to safely share simple data types (like an `int` or `float`) between processes.\n",
    "\n",
    "- **`typecode_or_type`** specifies the data type, using either a ctypes type or a one-letter typecode (like `'i'` for integer).\n",
    "- **`*args`** are passed to the constructor of the specified type.\n",
    "- **`lock`** controls access:\n",
    "  - `True` (default): uses an internal recursive lock for thread-safe access.\n",
    "  - `False`: disables synchronization (not safe for concurrent writes).\n",
    "  - You can also pass your own `Lock` or `RLock`.\n",
    "\n",
    "To modify the value safely in concurrent settings, **wrap the operation in a lock**:\n",
    "\n",
    "```python\n",
    "with counter.get_lock():\n",
    "    counter.value += 1\n",
    "```\n",
    "\n",
    "This is necessary because operations like `+=` are **not atomic** — they involve both reading and writing the value.\n",
    "\n",
    "Here's a **summarized and paraphrased** version of the documentation for `multiprocessing.Array`:\n",
    "\n",
    "---\n",
    "\n",
    "####  `multiprocessing.Array(typecode_or_type, size_or_initializer, *, lock=True)`\n",
    "\n",
    "Creates a **shared array** in memory for use across multiple processes, with optional synchronization.\n",
    "\n",
    "- **`typecode_or_type`** defines the element type, using either a ctypes type or a one-character typecode (like `'i'` for integers).\n",
    "- **`size_or_initializer`** can be:\n",
    "  - An **integer**: creates a zero-initialized array of that length.\n",
    "  - A **sequence**: initializes the array with the given values, and the sequence’s length sets the array size.\n",
    "- **`lock`** controls concurrent access:\n",
    "  - `True` (default): uses an internal lock for safe access.\n",
    "  - `False`: no locking — not safe for simultaneous writes.\n",
    "  - You can also pass a custom `Lock` or `RLock`.\n",
    "\n",
    "The returned object is a synchronized wrapper unless `lock=False`.\n",
    "\n",
    "---\n",
    "\n",
    "The following shows common type codes:\n",
    "\n",
    "| Type      | Typecode | Description              |\n",
    "|-----------|----------|--------------------------|\n",
    "| `int`     | `'i'`    | Signed integer (4 bytes) |\n",
    "| `double`  | `'d'`    | Double-precision float   |\n",
    "| `float`   | `'f'`    | Single-precision float   |\n",
    "| `char`    | `'c'`    | Char (1 byte, `bytes`)   |\n",
    "| `byte`    | `'b'`    | Signed char (-128 to 127)|\n",
    "\n",
    "**See practical example 6**.\n",
    "\n",
    "#### `multiprocessing.sharedctypes` module\n",
    "\n",
    "The `multiprocessing.sharedctypes` module offers more flexibility than `Value` and `Array` by allowing you to create arbitrary `ctypes` structures in shared memory.\n",
    "\n",
    "It allows you to:\n",
    "\n",
    "- Define custom `ctypes` structures, arrays, and types\n",
    "- Allocate them in shared memory so multiple processes can access them\n",
    "- Use familiar `ctypes` declarations (e.g. `c_int`, `c_double`, `Structure`, etc.)\n",
    "\n",
    "**See practical example 7**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793c8855",
   "metadata": {},
   "source": [
    "### Server process\n",
    "\n",
    "#### `multiprocessing.Manager()`\n",
    "\n",
    "In short, server process via `multiprocessing.Manager()` has the following properties:\n",
    "\n",
    "- Creates proxy objects (e.g. `list`, `dict`) for sharing more complex data.\n",
    "- Slower than `Value`/`Array` — works via a server process and proxy objects, not true shared memory.\n",
    "- Easier for things like shared dictionaries, nested structures.\n",
    "\n",
    "An object created by `multiprocessing.Manager()` runs a **server process** that hosts Python objects, allowing multiple processes to interact with those objects through **proxies**. Managers provide a way to create data which can be shared between different processes, including sharing over a network between processes running on different machines. A manager object controls a server process which manages shared objects. Other processes can access the shared objects by using proxies.\n",
    "\n",
    "A **proxy** is an object that acts as a **remote reference** to a shared object managed by a `Manager`.\n",
    "\n",
    "Instead of giving each process direct access to the actual object (which might live in a different memory space), the manager gives them a **proxy object**. This proxy communicates with the manager's **server process** under the hood to:\n",
    "- Get or set data\n",
    "- Call methods\n",
    "- Synchronize access\n",
    "\n",
    "The manager can be used to create and manage shared versions of common data types such as `list`, `dict`, `Namespace`, and threading synchronization primitives like `Lock`, `RLock`, `Semaphore`, `Condition`, `Event`, `Barrier`, as well as shared `Queue`, `Value`, and `Array` objects.\n",
    "\n",
    "**See practical example 8**.\n",
    "\n",
    "#### Customized managers\n",
    "\n",
    "**Customized managers** allow you to extend or register your own types to be shared between processes via proxies, beyond the built-in ones like `list`, `dict`, etc.\n",
    "\n",
    "A customized manager is created by:\n",
    "1. Subclassing `multiprocessing.managers.BaseManager`.\n",
    "2. Registering custom classes or callables via `register()` classmethod.\n",
    "3. Starting the manager to allow processes to access the shared objects via proxies.\n",
    "\n",
    "**See practical example 9**.\n",
    "\n",
    "#### Remote managers\n",
    "\n",
    "**Remote managers** allows you to share Python objects across machines or over a network, not just between processes on the same system. This is a powerful way to build distributed systems using the same proxy model.\n",
    "\n",
    "A remote manager is an instance of `BaseManager` that:\n",
    "- Runs a server process on a specific `host:port`\n",
    "- Exposes shared objects to other Python processes, even on different machines\n",
    "- Clients connect to this manager and use proxies to interact with the shared objects\n",
    "\n",
    "\n",
    "##### Server code\n",
    "\n",
    "**See practical example 10.1**.\n",
    "\n",
    "##### Clients code\n",
    "\n",
    "**See practical example 10.2 and 10.3**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b22e2d",
   "metadata": {},
   "source": [
    "## A pool of workers\n",
    "\n",
    "The `multiprocessing.Pool` class allows you to manage a **group of worker processes** that can handle tasks concurrently. You can submit jobs to this pool, and it will distribute them among the available workers.\n",
    "\n",
    "- The pool supports **parallel map operations** and can handle **asynchronous jobs**, including **timeouts** and **callbacks**.\n",
    "- Only the **process that creates the pool** should call its methods.\n",
    "\n",
    "Here's a short description of some key functions in the `multiprocessing.Pool`:\n",
    "\n",
    "**Pool methods:**\n",
    "\n",
    "- **`pool.map(function, iterable)`**: Applies a function to each item in an iterable in parallel and returns results in the original order. Blocks until all tasks complete.\n",
    "\n",
    "- **`pool.imap_unordered(function, iterable)`**: Similar to map, but lazier and returns results as soon as they're ready, regardless of input order. Can be faster when processing times vary.\n",
    "\n",
    "- **`pool.apply(function, args)`**: Applies a function with the given arguments. Runs in only one process and blocks until completion. Rarely used due to its blocking nature.\n",
    "\n",
    "- **`pool.apply_async(function, args)`**: Non-blocking version of apply. Returns a result object immediately while computation happens in the background. Use `result.get()` to retrieve the actual result when needed.\n",
    "\n",
    "**AsyncResult methods:**\n",
    "\n",
    "- **`result.get(timeout=None)`**: Retrieves the result of an async operation. If `timeout` is specified and the operation takes longer, raises `TimeoutError`.\n",
    "\n",
    "- **`result.ready()`**: Returns `True` if the call has completed.\n",
    "\n",
    "- **`result.successful()`**: Returns `True` if the call completed without raising an exception. Will raise `ValueError` if the result is not ready.\n",
    "\n",
    "**See practical example 11**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed4cac8",
   "metadata": {},
   "source": [
    "## CPU-bound task\n",
    "\n",
    "We already know that in Python CPU-intensive tasks are best handled with `multiprocessing` rather than `threading`, mainly due to the limitations of the Global Interpreter Lock (GIL).\n",
    "\n",
    "The GIL ensures that only one thread executes Python bytecode at a time, even on multi-core processors. This means that:\n",
    "\n",
    "- Threading does not provide real parallelism for CPU-bound tasks.\n",
    "- Threads still take turns using the CPU, resulting in limited performance gain or even overhead from context switching.\n",
    "- In contrast, multiprocessing creates separate processes, each with its own Python interpreter and memory space, allowing for true parallel execution across multiple CPU cores.\n",
    "\n",
    "Key points\n",
    "\n",
    "- Multiprocessing bypasses the GIL, enabling full CPU core usage.\n",
    "- Threading is limited by the GIL for CPU-bound work.\n",
    "- Multiprocessing is ideal for tasks like number crunching, image processing, or simulations.\n",
    "- Threading is better suited for I/O-bound tasks (e.g., file reads, network requests).\n",
    "\n",
    "In summary, due to the GIL, `threading` is ineffective for CPU-heavy workloads, whereas `multiprocessing` provides actual parallelism and improved performance.\n",
    "\n",
    "Let's see this in action with one more example.\n",
    "\n",
    "### Prime number checking\n",
    "\n",
    "**See practical example 12**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f899ad",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [multiprocessing — Process-based parallelism](https://docs.python.org/3/library/multiprocessing.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ed835b",
   "metadata": {},
   "source": [
    "## Concurrent Executors and Futures\n",
    "\n",
    "Python's `concurrent.futures` module provides a high-level interface for asynchronously executing tasks using threads or processes. It combines clean syntax with powerful concurrent programming capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5898ae3",
   "metadata": {},
   "source": [
    "### Key Components\n",
    "\n",
    "#### Executors\n",
    "\n",
    "The `concurrent.futures` module provides two primary executor classes:\n",
    "\n",
    "1. `ThreadPoolExecutor`: Uses threads for concurrent execution\n",
    "\n",
    "```python\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    # Submit tasks to be executed concurrently\n",
    "```\n",
    "\n",
    "2. `ProcessPoolExecutor`: Uses processes for concurrent execution\n",
    "\n",
    "```python\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    # Submit tasks to be executed concurrently\n",
    "```\n",
    "\n",
    "#### Futures\n",
    "\n",
    "A `concurrent.futures.Future` represents the result of an asynchronous computation. It's a placeholder for a value that will be available when the computation completes. It's used to check on, retrieve, or cancel the result of a function submitted to an executor (via `Executor.submit()`).\n",
    "\n",
    "Some key methods:\n",
    "\n",
    "1. **`result(timeout=None)`**\n",
    "   - Returns the result of the computation.\n",
    "   - Blocks until the result is ready or `timeout` is reached.\n",
    "   - Raises the exception if the function raised one.\n",
    "\n",
    "2. **`exception(timeout=None)`**\n",
    "   - Returns the exception raised by the function (if any), or `None`.\n",
    "   - Blocks like `result()`.\n",
    "\n",
    "3. **`done()`**\n",
    "   - Returns `True` if the computation is complete (with or without success).\n",
    "\n",
    "4. **`cancel()`**\n",
    "   - Attempts to cancel the execution.\n",
    "   - Returns `True` if successfully cancelled.\n",
    "\n",
    "5. **`cancelled()`**\n",
    "   - Returns `True` if the future was cancelled.\n",
    "\n",
    "6. **`running()`**\n",
    "   - Returns `True` if the function is currently being executed.\n",
    "\n",
    "7. **`add_done_callback(fn)`**\n",
    "   - Attaches a callable to be run when the future is done.\n",
    "\n",
    "```python\n",
    "future = executor.submit(function, arg1, arg2)  # Returns immediately\n",
    "\n",
    "# Check if done without blocking\n",
    "if future.done():\n",
    "    print(\"Task completed\")\n",
    "\n",
    "# Get result (will block until ready)\n",
    "result = future.result()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e443b5a3",
   "metadata": {},
   "source": [
    "### `concurrent.futures.ThreadPoolExecutor`\n",
    "\n",
    "An `concurrent.futures.Executor` subclass that uses a pool of at most `max_workers` (given as an argument) threads to execute calls asynchronously.\n",
    "\n",
    "All threads enqueued to `ThreadPoolExecutor` will be joined before the interpreter can exit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624b6ad9",
   "metadata": {},
   "source": [
    "### `concurrent.futures.ProcessPoolExecutor`\n",
    "\n",
    "`ProcessPoolExecutor` is a high-level interface `concurrent.futures` module that allows you to run CPU-bound tasks in separate processes concurrently. It's part of Python’s standard library and provides a simple way to achieve parallelism using multiple processes, as opposed to `ThreadPoolExecutor` which uses threads (better for I/O-bound tasks)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
