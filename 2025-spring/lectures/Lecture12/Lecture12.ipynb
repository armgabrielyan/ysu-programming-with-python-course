{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91a9302f",
   "metadata": {},
   "source": [
    "# Programming with Python\n",
    "\n",
    "## Lecture 12: Concurrency 4\n",
    "\n",
    "### Armen Gabrielyan\n",
    "\n",
    "#### Yerevan State University / ASDS\n",
    "\n",
    "#### 10 May, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540d4bc3",
   "metadata": {},
   "source": [
    "# Multi-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed4cac8",
   "metadata": {},
   "source": [
    "## CPU-bound task\n",
    "\n",
    "We already know that in Python CPU-intensive tasks are best handled with `multiprocessing` rather than `threading`, mainly due to the limitations of the Global Interpreter Lock (GIL).\n",
    "\n",
    "The GIL ensures that only one thread executes Python bytecode at a time, even on multi-core processors. This means that:\n",
    "\n",
    "- Threading does not provide real parallelism for CPU-bound tasks.\n",
    "- Threads still take turns using the CPU, resulting in limited performance gain or even overhead from context switching.\n",
    "- In contrast, multiprocessing creates separate processes, each with its own Python interpreter and memory space, allowing for true parallel execution across multiple CPU cores.\n",
    "\n",
    "Key points\n",
    "\n",
    "- Multiprocessing bypasses the GIL, enabling full CPU core usage.\n",
    "- Threading is limited by the GIL for CPU-bound work.\n",
    "- Multiprocessing is ideal for tasks like number crunching, image processing, or simulations.\n",
    "- Threading is better suited for I/O-bound tasks (e.g., file reads, network requests).\n",
    "\n",
    "In summary, due to the GIL, `threading` is ineffective for CPU-heavy workloads, whereas `multiprocessing` provides actual parallelism and improved performance.\n",
    "\n",
    "Let's see this in action with one more example.\n",
    "\n",
    "### Prime number checking\n",
    "\n",
    "**See practical example 1**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f899ad",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [multiprocessing — Process-based parallelism](https://docs.python.org/3/library/multiprocessing.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5898ae3",
   "metadata": {},
   "source": [
    "# Concurrent Executors and Futures\n",
    "\n",
    "Python's `concurrent.futures` module provides a high-level interface for asynchronously executing tasks using threads or processes. It combines clean syntax with powerful concurrent programming capabilities.\n",
    "\n",
    "## Key Components\n",
    "\n",
    "### Futures\n",
    "\n",
    "A `concurrent.futures.Future` represents the result of an asynchronous computation. It's a placeholder for a value that will be available when the computation completes. It's used to check on, retrieve, or cancel the result of a function submitted to an executor (via `Executor.submit()`).\n",
    "\n",
    "Some key methods:\n",
    "\n",
    "1. **`result(timeout=None)`**\n",
    "   - Returns the result of the computation.\n",
    "   - Blocks until the result is ready or `timeout` is reached.\n",
    "   - Raises the exception if the function raised one.\n",
    "\n",
    "2. **`exception(timeout=None)`**\n",
    "   - Returns the exception raised by the function (if any), or `None`.\n",
    "   - Blocks like `result()`.\n",
    "\n",
    "3. **`done()`**\n",
    "   - Returns `True` if the computation is complete (with or without success).\n",
    "\n",
    "4. **`cancel()`**\n",
    "   - Attempt to cancel the call. If the call is currently being executed or finished running and cannot be cancelled then the method will return `False`, otherwise the call will be cancelled and the method will return `True`.\n",
    "\n",
    "5. **`cancelled()`**\n",
    "   - Returns `True` if the future was cancelled.\n",
    "\n",
    "6. **`running()`**\n",
    "   - Returns `True` if the function is currently being executed.\n",
    "\n",
    "7. **`add_done_callback(fn)`**\n",
    "   - Attaches a callable to be run when the future is done.\n",
    "\n",
    "```python\n",
    "future = executor.submit(function, arg1, arg2)  # Returns immediately\n",
    "\n",
    "# Check if done without blocking\n",
    "if future.done():\n",
    "    print(\"Task completed\")\n",
    "\n",
    "# Get result (will block until ready)\n",
    "result = future.result()\n",
    "```\n",
    "\n",
    "### Executors\n",
    "\n",
    "A `concurrent.futures.Executor` is an abstract base class for asynchronous execution of tasks. It isn’t used directly—instead, you use one of its subclasses like `concurrent.futures.ThreadPoolExecutor` or `concurrent.futures.ProcessPoolExecutor`.\n",
    "\n",
    "`Executor`'s key methods are:\n",
    "\n",
    "1. **`submit(fn, *args, **kwargs)`**\n",
    "- Schedules a function `fn` to run with the given arguments.\n",
    "- Returns a `Future` object representing the eventual result.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "    future = executor.submit(pow, 323, 1235)\n",
    "    print(future.result())\n",
    "```\n",
    "\n",
    "2. **`map(fn, *iterables, timeout=None, chunksize=1)`**\n",
    "- Works like the built-in `map()`, but executes function calls concurrently.\n",
    "- Collects all inputs up front.\n",
    "- Returns an iterator over results.\n",
    "- Supports a `timeout` to limit how long it waits for results.\n",
    "- In `ProcessPoolExecutor`, tasks are split into chunks (controlled by `chunksize`) for performance. `ThreadPoolExecutor` ignores `chunksize`.\n",
    "\n",
    "3. **`shutdown(wait=True, cancel_futures=False)`**\n",
    "- Cleans up executor resources once tasks finish.\n",
    "- After calling `shutdown()`, you can’t submit new tasks.\n",
    "- If `wait=True`, the call waits until all tasks complete.\n",
    "- If `cancel_futures=True`, it cancels tasks that haven’t started yet.\n",
    "\n",
    "**Best practice:** Use the `with` statement to ensure proper cleanup:\n",
    "\n",
    "```python\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    executor.submit(shutil.copy, 'src1.txt', 'dest1.txt')\n",
    "    # Submit more copy tasks...\n",
    "```\n",
    "\n",
    "The `concurrent.futures` module provides two primary executor classes:\n",
    "\n",
    "1. `ThreadPoolExecutor`: Uses threads for concurrent execution\n",
    "\n",
    "```python\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    # Submit tasks to be executed concurrently\n",
    "```\n",
    "\n",
    "2. `ProcessPoolExecutor`: Uses processes for concurrent execution\n",
    "\n",
    "```python\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    # Submit tasks to be executed concurrently\n",
    "```\n",
    "\n",
    "### Module functions\n",
    "\n",
    "1. **`concurrent.futures.wait(fs, timeout=None, return_when=ALL_COMPLETED)`**\n",
    "\n",
    "This function waits for a group of `Future` objects (from one or more executors) to complete.\n",
    "\n",
    "- **Parameters:**\n",
    "  - `fs`: A collection of `Future` instances.\n",
    "  - `timeout`: Maximum time (in seconds) to wait. If not set or `None`, it waits indefinitely.\n",
    "  - `return_when`: Determines when the function returns. Can be:\n",
    "    - `FIRST_COMPLETED`: Returns as soon as one future is done or cancelled.\n",
    "    - `FIRST_EXCEPTION`: Returns when any future raises an exception.\n",
    "    - `ALL_COMPLETED`: Waits until all futures are finished or cancelled.\n",
    "\n",
    "- **Returns:** A named 2-tuple of sets:\n",
    "  - `done`: Futures that are completed (including cancelled).\n",
    "  - `not_done`: Futures still running or waiting.\n",
    "\n",
    "\n",
    "2. **`concurrent.futures.as_completed(fs, timeout=None)`**\n",
    "\n",
    "This function provides an iterator that yields futures in the order they finish.\n",
    "\n",
    "- **Parameters:**\n",
    "  - `fs`: A group of `Future` objects.\n",
    "  - `timeout`: Time limit in seconds for waiting on each result. If not set or `None`, it waits indefinitely.\n",
    "\n",
    "- **Behavior:**\n",
    "  - Already-finished futures are yielded first.\n",
    "  - Yields each future as soon as it completes.\n",
    "  - Raises `TimeoutError` if a future doesn't complete within the timeout when iterating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e443b5a3",
   "metadata": {},
   "source": [
    "### `concurrent.futures.ThreadPoolExecutor`\n",
    "\n",
    "An `concurrent.futures.Executor` subclass that uses a pool of at most `max_workers` (given as an argument) threads to execute calls asynchronously.\n",
    "\n",
    "All threads enqueued to `ThreadPoolExecutor` will be joined before the interpreter can exit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624b6ad9",
   "metadata": {},
   "source": [
    "### `concurrent.futures.ProcessPoolExecutor`\n",
    "\n",
    "`ProcessPoolExecutor` is a high-level interface `concurrent.futures` module that allows you to run CPU-bound tasks in separate processes concurrently. It's part of Python’s standard library and provides a simple way to achieve parallelism using multiple processes, as opposed to `ThreadPoolExecutor` which uses threads (better for I/O-bound tasks)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93c517b",
   "metadata": {},
   "source": [
    "### Practical examples\n",
    "\n",
    "**See practical example 2 about *futures***.\n",
    "\n",
    "**See practical example 3 about *executors***.\n",
    "\n",
    "**See practical example 4 about *thread pool executors***.\n",
    "\n",
    "**See practical example 5 about *thread pool executors***.\n",
    "\n",
    "**See practical example 6 about *web scraper***.\n",
    "\n",
    "**See practical example 7 about *prime checking***."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42773235",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [concurrent.futures — Launching parallel tasks](https://docs.python.org/3/library/concurrent.futures.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c065bd60",
   "metadata": {},
   "source": [
    "# Async programming with Async IO\n",
    "\n",
    "**Asynchronous programming** is a powerful paradigm for writing efficient, non-blocking code and Python's Async IO framework provides excellent tools for implementing it. Async IO is built around coroutines, event loops and the `async`/`await` syntax. The basic idea is to allow tasks to pause execution while waiting for slow operations (like network or file I/O), letting other tasks run during that wait time.\n",
    "\n",
    "Async IO is a *single-threaded, single-process design* that uses **cooperative multitasking**. This is a fundamental characteristic that distinguishes it from other concurrency models:\n",
    "\n",
    "1. **Single thread** - All code runs on a single thread, unlike threading or multiprocessing.   \n",
    "2. **Explicit yield points** - Tasks voluntarily yield control at `await` statements, allowing other tasks to run.\n",
    "3. **Non-preemptive** - The scheduler doesn't interrupt tasks; they must cooperate by yielding control.\n",
    "4. **Event loop coordination** - The event loop manages the scheduling of coroutines as they yield control.\n",
    "\n",
    "This cooperative approach means tasks must be well-behaved - a task that performs CPU-intensive operations without yielding will block the entire event loop, preventing other tasks from running.\n",
    "\n",
    "### Async IO explained\n",
    "\n",
    "Async IO may at first seem counterintuitive and paradoxical. How does something that facilitates concurrent code use a single thread and a single CPU core? Miguel Grinberg’s 2017 PyCon talk explains everything quite beautifully:\n",
    "\n",
    "> Chess master Judit Polgár hosts a chess exhibition in which she plays multiple amateur players. She has two ways of conducting the exhibition: synchronously and asynchronously.\n",
    ">\n",
    "> Assumptions:\n",
    ">\n",
    "> - 24 opponents\n",
    "> - Judit makes each chess move in 5 seconds\n",
    "> - Opponents each take 55 seconds to make a move\n",
    "> - Games average 30 pair-moves (60 moves total)\n",
    ">\n",
    "> **Synchronous version:** Judit plays one game at a time, never two at the same time, until the game is complete. > Each game takes (55 + 5) * 30 == 1800 seconds, or 30 minutes. The entire exhibition takes 24 * 30 == 720 minutes, or *12 hours*.\n",
    "> \n",
    "> **Asynchronous version:** Judit moves from table to table, making one move at each table. She leaves the table and lets the opponent make their next move during the wait time. One move on all 24 games takes Judit 24 * 5 == 120 seconds, or 2 minutes. The entire exhibition is now cut down to 120 * 30 == 3600 seconds, or just *1 hour*. \n",
    ">\n",
    "> [Source](https://www.youtube.com/watch?v=iG6fr81xHKA&t=269s)\n",
    "\n",
    "## Key components:\n",
    "\n",
    "1. **(Native) Coroutines**: Functions defined with `async def` that can be paused at `await` points to let other coroutines run and later be resumed.\n",
    "2. **Event loop**: The central execution mechanism that runs and manages coroutines.\n",
    "3. **Tasks**: Wrapped coroutines that run concurrently in the event loop.\n",
    "4. **Awaitables**: Objects that can be used with the `await` keyword (coroutines, Tasks, Futures)\n",
    "\n",
    "Async IO is built into `asyncio` library, which is to write concurrent code using the `async/await` syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9b098f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f738a",
   "metadata": {},
   "source": [
    "### Intro to `asyncio` functions\n",
    "\n",
    "- `asyncio.sleep(delay, result=None)` is an awaitable, meaning it can be used with `await` to pause the coroutine. Its a coroutine that suspends the current task, allowing other tasks to run. While `time.sleep()` can represent any time-consuming blocking function call, `asyncio.sleep()` is used to stand in for a non-blocking call (but one that also takes some time to complete).\n",
    "- `asyncio.run(coro, *, debug=None, loop_factory=None)` is a function that executes the coroutine `coro` and returns the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09351ef",
   "metadata": {},
   "source": [
    "## Coroutines\n",
    "\n",
    "**Coroutines** are the foundation of Async IO's cooperative multitasking model. They're special functions that can pause execution, yield control back to the event loop and later resume from where they left off.\n",
    "\n",
    "1. **Definition**: Native coroutines are defined using the `async def` syntax\n",
    "2. **Suspension Points**: They can suspend execution at `await` expressions\n",
    "3. **State Preservation**: When suspended, they maintain their state (local variables, execution position)\n",
    "4. **Non-blocking**: They don't block the thread while waiting for operations to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02fcf17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def say_hello():\n",
    "    print(\"Hello\")\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7edc3773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.say_hello()>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "say_hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5a8175f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object say_hello at 0x1238f0640>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "say_hello()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6f5066",
   "metadata": {},
   "source": [
    "**See practical example 8.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c5056e",
   "metadata": {},
   "source": [
    "### More `asyncio` functions\n",
    "\n",
    "- #### `asyncio.gather(*aws, return_exceptions=False)`\n",
    "\n",
    "Run awaitable objects in the `aws` sequence concurrently. It is used to run multiple coroutines at the same time, and wait until all of them complete.\n",
    "\n",
    "If `return_exceptions` is `False` (default), the first raised exception is immediately propagated to the task that awaits on `gather()`. Other awaitables in the `aws` sequence won’t be cancelled and will continue to run.\n",
    "\n",
    "If `return_exceptions` is `True`, exceptions are treated the same as successful results, and aggregated in the result list.\n",
    "\n",
    "**See practical example 9.**\n",
    "\n",
    "**See practical example 10.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
